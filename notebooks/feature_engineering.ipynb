{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter\n",
    "from math import sin, cos, sqrt, atan2, radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "PROCESSED_PATH = Path('../data/processed/')\n",
    "listings = pd.read_csv(PROCESSED_PATH/'cleaned_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22472 entries, 0 to 22471\n",
      "Data columns (total 29 columns):\n",
      "summary                         21535 non-null object\n",
      "space                           13957 non-null object\n",
      "description                     22270 non-null object\n",
      "neighbourhood_overview          11506 non-null object\n",
      "notes                           7188 non-null object\n",
      "transit                         12999 non-null object\n",
      "access                          10807 non-null object\n",
      "interaction                     10351 non-null object\n",
      "house_rules                     11395 non-null object\n",
      "neighbourhood_group_cleansed    22472 non-null object\n",
      "latitude                        22472 non-null float64\n",
      "longitude                       22472 non-null float64\n",
      "is_location_exact               22472 non-null int64\n",
      "property_type                   22472 non-null object\n",
      "room_type                       22472 non-null object\n",
      "accommodates                    22472 non-null int64\n",
      "bathrooms                       22472 non-null float64\n",
      "bedrooms                        22472 non-null float64\n",
      "beds                            22472 non-null float64\n",
      "amenities                       22472 non-null object\n",
      "square_feet                     446 non-null float64\n",
      "price                           22472 non-null float64\n",
      "cleaning_fee                    22472 non-null float64\n",
      "guests_included                 22472 non-null int64\n",
      "extra_people                    22472 non-null float64\n",
      "minimum_nights                  22472 non-null int64\n",
      "maximum_nights                  22472 non-null int64\n",
      "instant_bookable                22472 non-null int64\n",
      "cancellation_policy             22472 non-null int64\n",
      "dtypes: float64(9), int64(7), object(13)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "listings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file I will create new features from the existing ones. Features to create:\n",
    "\n",
    "1. Indicator variables:\n",
    "    - Neighbourhood overview\n",
    "    - Interaction\n",
    "    - House rules\n",
    "    - Transit\n",
    "1. Create a total price (price + cleaning fee) as another potential target variable.\n",
    "1. Distance from different landmarks.\n",
    "1. Amenities dummy variables and total number of amenities.\n",
    "1. Square feet from description.\n",
    "1. Investigate other features to see if any other information could be gained.\n",
    "\n",
    "## Indicator Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indicator_variable(dataframe, col):\n",
    "    indicator = dataframe[col].notnull().astype('int')\n",
    "    indicator.name = indicator.name + '_indicator'\n",
    "    \n",
    "    return pd.concat([dataframe, indicator], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_cols = ['neighbourhood_overview', 'interaction', 'house_rules', 'transit']\n",
    "for col in indicator_cols:\n",
    "    listings = create_indicator_variable(listings, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Price\n",
    "\n",
    "I want a total price that includes the cleaning fee, to see if this is a better target variable to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['total_price'] = listings['price'] + listings['cleaning_fee']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance From Landmarks\n",
    "\n",
    "I suspect that listings that are within walking distance or closer to the popular tourist spots may be worth more. Using the latitude and logitude of the listing I can find out the distance (as the crow flies) from lots of popular landmarks. I will find the latitude and longitude of multiple different landmarks and compute the km from these landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longlat_to_km(origin, destination):\n",
    "    \"\"\"\n",
    "    Function that computes the distance between two (lat, long) points.\n",
    "    \"\"\"\n",
    "    radius = 6371 # km\n",
    "    lat1, long1 = origin\n",
    "    lat2, long2 = destination\n",
    "    \n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlong = radians(long2 - long1)\n",
    "    \n",
    "    a = sin(dlat / 2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlong / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = radius * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = {\n",
    "    'Centre': (52.5200, 13.4050),\n",
    "    'Brandenburg_Gate': (52.516266, 13.377775),\n",
    "    'Berlin_Wall': (52.535152, 13.390206),\n",
    "    'Reichstag': (52.518589, 13.376665),\n",
    "    'Museum_Island': (52.516640, 13.402318),\n",
    "    'Central_Station': (52.524929, 13.369181),\n",
    "    'Telivision_Tower': (52.520817, 13.409419)\n",
    "} # Coordinates found from latlong.net\n",
    "for landmark, coordinates in landmarks.items():\n",
    "    listings[f'distance_from_{landmark}'] = listings.apply(\n",
    "        lambda listing: longlat_to_km((listing[\"latitude\"], listing[\"longitude\"]), coordinates), axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can remove the latitude and longitude columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.drop(['latitude', 'longitude'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amenities\n",
    "\n",
    "Using the amenities feature I will compute dummy variables to indicate if the listing has the amenity and also a total amenities feature to indicate how many amenities the listing includes. Currently our amenities are stored as a string with each amenity seperated by a comma, firstly I will transform my amenities into a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['amenities'] = listings['amenities'].apply(lambda x: set(re.sub('[{}\"]', '', x).split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a feature that tells us the number of amenities a listing offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['amenities_count'] = listings['amenities'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a counter object to get a set of all the different amenities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenity_counter = Counter()\n",
    "listings['amenities'].apply(lambda x: amenity_counter.update(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to include amenities that either have a high occurance or a low occurance in our model as they do not tell us very much. We should only include amenities over some variance threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenity_prev = [(amenity, c/len(listings)) for amenity, c in amenity_counter.most_common()]\n",
    "amenity_var = [(amenity, p*(1-p)) for amenity, p in amenity_prev]\n",
    "var_threshold = 0.8 * (1 - 0.8)\n",
    "amenities_to_include = [amenity for amenity, var in amenity_var if var > var_threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create dummy variables for all the amenities we want to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for amenity in amenities_to_include:\n",
    "    listings[amenity] = listings['amenities'].apply(lambda x: np.where(amenity in x, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.drop('amenities', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size\n",
    "\n",
    "We already have a squared_feet column but this is missing a large amount of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.01530793876825"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * listings['square_feet'].isnull().sum() / len(listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking through the descriptions of some of the listings some of the listings give the square meters of the apartment. This is usually in the form __ sqm/square meters. Some of the listings give the square meters and the square feet, we should take the minimum of these values to get sqm. First lets gain as much information from the description as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_size(description):\n",
    "    \"\"\"\n",
    "    Returns the size of the listing when the description has a value followed\n",
    "    by one of the size unit patterns and the value is within acceptable bounds.\n",
    "    \"\"\"\n",
    "    if description is np.nan:\n",
    "        return np.nan\n",
    "    pattern = u'(?i)\\s\\d+\\s?(?=sq\\w*\\s?m|m2|m\\u00B2|ms?q|qm|m/2|meters?\\s?sq)'\n",
    "    sizes = [float(x.strip()) for x in re.findall(pattern, description)]\n",
    "    sizes = list(filter(lambda x: x<=300 and x>10, sizes))\n",
    "    if not sizes:\n",
    "        return np.nan\n",
    "    return min(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['square_meters'] = listings['description'].apply(find_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5054.000000\n",
       "mean       55.087060\n",
       "std        40.267642\n",
       "min        11.000000\n",
       "25%        24.000000\n",
       "50%        43.500000\n",
       "75%        75.000000\n",
       "max       300.000000\n",
       "Name: square_meters, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings['square_meters'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have managed to get a fair amount of information from the description, let's see if any of the other descritive columns contain additional information about the size of the listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5166"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in ['summary', 'space', 'notes']:\n",
    "    listings['square_meters'] = listings['square_meters'].fillna(listings[col].apply(find_size))\n",
    "listings['square_meters'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to get a size for an extra 112 listings, now we can use the feet_squared feature to fill missing values and convert to meters squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feet_to_meters(measurement):\n",
    "    \"\"\"Return m2 from ft2\"\"\"\n",
    "    return measurement/10.764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_square_meters(listing):\n",
    "    \"\"\"\n",
    "    Convert ft2 feature to m2 if squared_meters is missing and the result is within reasonable bounds.\n",
    "    \"\"\"\n",
    "    if not np.isnan(listing['square_feet']) and listing['square_feet']>0:\n",
    "        if np.isnan(listing['square_meters']):\n",
    "            value = feet_to_meters(listing['square_feet'])\n",
    "            value_conditional = value<250 and value>10\n",
    "            return value if value_conditional else np.nan\n",
    "    return listing['square_meters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5364"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings['square_meters'] = listings.apply(fill_square_meters, axis=1)\n",
    "listings['square_meters'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We couldn't gain any extra information from the square_feet column, we can drop the squared_feet column now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.drop('square_feet', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much of the square meters column is missing information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.13029547881808"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * listings['square_meters'].isnull().sum() / len(listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How important is the information we have gained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_price            0.485633\n",
       "bedrooms               0.457441\n",
       "price                  0.453087\n",
       "accommodates           0.432057\n",
       "beds                   0.370702\n",
       "cleaning_fee           0.349272\n",
       "bathrooms              0.346051\n",
       "guests_included        0.282991\n",
       "Family/kid friendly    0.252436\n",
       "amenities_count        0.214925\n",
       "Name: square_meters, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings.corr()['square_meters'][listings.corr()['square_meters'] > 0.2].sort_values(ascending=False)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square_meters feature has a fairly high correlation with price and total price. This shows it could be very useful to our model. We should try and fill in the missing information using a machine learning algorithm. First lets create dummy columns from columns I think could help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = ['room_type', 'property_type', 'neighbourhood_group_cleansed']\n",
    "dummies = pd.get_dummies(listings[dummy_cols], drop_first=True)\n",
    "\n",
    "predictor_cols = [\n",
    "    'bedrooms',\n",
    "    'accommodates',\n",
    "    'beds',\n",
    "    'cleaning_fee',\n",
    "    'bathrooms',\n",
    "    'square_meters',\n",
    "    'Family/kid friendly'\n",
    "]\n",
    "listings_size_predictors_all = pd.concat([listings[predictor_cols], dummies], axis=1)\n",
    "listings_size_predictors = listings_size_predictors_all[listings_size_predictors_all['square_meters'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets test some linear models to see which will model our problem best. First lets split our data into a training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "X = listings_size_predictors.drop('square_meters', axis=1)\n",
    "y = listings_size_predictors['square_meters']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1184.1141088715688\n",
      "RMSE 34.41095913908197\n",
      "MAE:  24.704369371817865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "lasso = LassoCV(alphas=[1e-3, 1e-2, 1e-1, 1], cv=10).fit(X_train, y_train)\n",
    "predictions = lasso.predict(X_test)\n",
    "print('MSE: ', mean_squared_error(y_test, predictions))\n",
    "print('RMSE', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('MAE: ', mean_absolute_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1188.3697259337782\n",
      "RMSE 34.472738880654354\n",
      "MAE:  24.729973026955108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "elasnet = ElasticNetCV(alphas=[1e-3, 1e-2, 1e-1, 1], cv=10).fit(X_train, y_train)\n",
    "predictions = elasnet.predict(X_test)\n",
    "print('MSE: ', mean_squared_error(y_test, predictions))\n",
    "print('RMSE', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('MAE: ', mean_absolute_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1195.21739698955\n",
      "RMSE 34.57191630484995\n",
      "MAE:  24.793971099156096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1], cv=10).fit(X_train, y_train)\n",
    "predictions = ridge.predict(X_test)\n",
    "print('MSE: ', mean_squared_error(y_test, predictions))\n",
    "print('RMSE', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('MAE: ', mean_absolute_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic net looks to give the best results, we can now fill the missing values using this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_sqm(listing, model):\n",
    "    if not np.isnan(listing['square_meters']):\n",
    "        return listing['square_meters']\n",
    "    predictors = listing.drop('square_meters').to_numpy().reshape(1,-1)\n",
    "    return model.predict(predictors)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['square_meters'] = listings_size_predictors_all.apply(\n",
    "    lambda x: impute_missing_sqm(x, elasnet), axis=1\n",
    ").astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can drop the columns we won't use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'summary',\n",
    "    'space',\n",
    "    'description',\n",
    "    'neighbourhood_overview',\n",
    "    'notes',\n",
    "    'transit',\n",
    "    'access',\n",
    "    'interaction',\n",
    "    'house_rules',\n",
    "]\n",
    "listings.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have finished feature engineering and we have our data for modelling, we can write the data to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.to_csv(PROCESSED_PATH/'listings_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berlin_airbnb",
   "language": "python",
   "name": "berlin_airbnb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
